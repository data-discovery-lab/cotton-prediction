{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_table('Data_28_F29.txt', delimiter=',')\n",
    "df = pd.read_csv('cotton_data_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns = ['AVGYLD','ELE','SLOPE','CURV', 'PRO','PLAN','EC_SH','EC_DP','BAND1','BAND2','BAND3','BAND4',\n",
    "#            'VI00_520','VI00_528','VI00_613','VI00_707','VI00_715','VI00_723','VI00_816','VI00_824','VI00_901','VI00_917',\n",
    "#            'VI01_616','VI01_624','VI01_710','VI01_827','VI01_912','VI02_518','VI02_526','VI02_619',\n",
    "#            'VI02_713','VI02_721','VI02_830','VI02_907','VI02_923','VI03_505','VI03_529','VI03_606',\n",
    "#            'VI03_622','VI03_724','VI03_825','VI03_926']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YLD00</th>\n",
       "      <th>ELE</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>CURV</th>\n",
       "      <th>PRO</th>\n",
       "      <th>PLAN</th>\n",
       "      <th>EC_SH</th>\n",
       "      <th>EC_DP</th>\n",
       "      <th>BAND1</th>\n",
       "      <th>BAND2</th>\n",
       "      <th>...</th>\n",
       "      <th>VI00_520</th>\n",
       "      <th>VI00_528</th>\n",
       "      <th>VI00_613</th>\n",
       "      <th>VI00_707</th>\n",
       "      <th>VI00_715</th>\n",
       "      <th>VI00_723</th>\n",
       "      <th>VI00_816</th>\n",
       "      <th>VI00_824</th>\n",
       "      <th>VI00_901</th>\n",
       "      <th>VI00_917</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012.799988</td>\n",
       "      <td>1080.06</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>14.4</td>\n",
       "      <td>38.700001</td>\n",
       "      <td>96</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2174</td>\n",
       "      <td>-0.1848</td>\n",
       "      <td>-0.1341</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.2242</td>\n",
       "      <td>0.3089</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>-0.0435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930.000000</td>\n",
       "      <td>1080.08</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>14.3</td>\n",
       "      <td>40.900002</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2082</td>\n",
       "      <td>-0.1802</td>\n",
       "      <td>-0.1742</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.2486</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>-0.0192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902.000000</td>\n",
       "      <td>1080.10</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>13.9</td>\n",
       "      <td>36.900002</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2014</td>\n",
       "      <td>-0.1802</td>\n",
       "      <td>-0.1625</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.2697</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>-0.0099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>931.900024</td>\n",
       "      <td>1080.13</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>14.1</td>\n",
       "      <td>37.099998</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2041</td>\n",
       "      <td>-0.1826</td>\n",
       "      <td>-0.1500</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>-0.0246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>885.000000</td>\n",
       "      <td>1080.18</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>-0.001229</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>14.8</td>\n",
       "      <td>36.099998</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2081</td>\n",
       "      <td>-0.1810</td>\n",
       "      <td>-0.1553</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.3604</td>\n",
       "      <td>0.4717</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>-0.0099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         YLD00      ELE   SLOPE      CURV       PRO      PLAN  EC_SH  \\\n",
       "0  1012.799988  1080.06  0.0879  0.002694 -0.001178  0.001515   14.4   \n",
       "1   930.000000  1080.08  0.0575  0.001403 -0.000473  0.000930   14.3   \n",
       "2   902.000000  1080.10  0.0906 -0.004624  0.004098 -0.000527   13.9   \n",
       "3   931.900024  1080.13  0.1291 -0.001335  0.001011 -0.000324   14.1   \n",
       "4   885.000000  1080.18  0.1515  0.002538 -0.001229  0.001309   14.8   \n",
       "\n",
       "       EC_DP  BAND1  BAND2    ...     VI00_520  VI00_528  VI00_613  VI00_707  \\\n",
       "0  38.700001     96     84    ...      -0.2174   -0.1848   -0.1341    0.1712   \n",
       "1  40.900002     94     91    ...      -0.2082   -0.1802   -0.1742    0.1378   \n",
       "2  36.900002     92     92    ...      -0.2014   -0.1802   -0.1625    0.1416   \n",
       "3  37.099998     96     89    ...      -0.2041   -0.1826   -0.1500    0.1217   \n",
       "4  36.099998     96     89    ...      -0.2081   -0.1810   -0.1553    0.1121   \n",
       "\n",
       "   VI00_715  VI00_723  VI00_816  VI00_824  VI00_901  VI00_917  \n",
       "0    0.2242    0.3089    0.1748    0.2216    0.1667   -0.0435  \n",
       "1    0.2486    0.3505    0.3377    0.3368    0.2500   -0.0192  \n",
       "2    0.2697    0.3571    0.4125    0.3069    0.2500   -0.0099  \n",
       "3    0.2849    0.3776    0.4750    0.4020    0.2270   -0.0246  \n",
       "4    0.2737    0.3604    0.4717    0.4257    0.1976   -0.0099  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use = df\n",
    "df_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['YLD00', 'ELE', 'SLOPE', 'CURV', 'PRO', 'PLAN', 'EC_SH', 'EC_DP',\n",
       "       'BAND1', 'BAND2', 'BAND3', 'BAND4', 'VI00_520', 'VI00_528',\n",
       "       'VI00_613', 'VI00_707', 'VI00_715', 'VI00_723', 'VI00_816',\n",
       "       'VI00_824', 'VI00_901', 'VI00_917'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "def compute_score(clf, X, y, scoring='mean_squared_error'):\n",
    "    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n",
    "    return np.mean(xval)\n",
    "\n",
    "def plot_roc(x_test, y_test, model):\n",
    "    predicted_probas = model.predict_proba(x_test)\n",
    "    skplt.metrics.plot_roc(y_test, predicted_probas, figsize =(10,10))\n",
    "    plt.show()\n",
    "    \n",
    "def yld_category(yld):\n",
    "    if yld <= 603:\n",
    "        return 1\n",
    "    elif 603 < yld <= 766:\n",
    "        return 2\n",
    "    elif 766 < yld <= 882:\n",
    "        return 3\n",
    "    elif 882 < yld <= 956:\n",
    "        return 4\n",
    "    elif 956 < yld <= 1018:\n",
    "        return 5\n",
    "    elif 1018 < yld <= 1075:\n",
    "        return 6\n",
    "    elif 1075 < yld <= 1134:\n",
    "        return 7\n",
    "    elif 1134 < yld <= 1200:\n",
    "        return 8\n",
    "    elif 1200 < yld <= 1280:\n",
    "        return 9\n",
    "    elif yld > 1280:\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = df_use\n",
    "full['AVGYLD_Category'] = full['YLD00'].apply(lambda x: yld_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b9fe3e1f60>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAELCAYAAADX3k30AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqIb0AgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b9fec6f3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(full['AVGYLD_Category'], kde=False, bins=10, hist_kws={'edgecolor':'white', 'alpha':1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b9fe49c160>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAELCAYAAADX3k30AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFQZJREFUeJzt3X+0ZWV93/H3pwOGgEmBcKGEH7nA\nGlEwOpArkhAtkagILpFWlGklo6UdbdFqY1ZEkxWNNg1J/JUsElyjINiSERQotBAjpSCLqtThh+OQ\ngciPEQamMzeQAq2izPDtH2ffchjvnXvnnnPnDM+8X2uddfZ5zt77+XJ0Pmff5+z97FQVkqR2/YNR\nFyBJWlgGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxu426AID99tuvxsfHR12G\nJD2v3HbbbX9XVWOzrbdTBP34+DirVq0adRmS9LyS5PtzWc+hG0lqnEEvSY0z6CWpcQa9JDXOoJek\nxhn0ktQ4g16SGjdr0Cc5JMmNSdYmuSvJ+7r2fZNcn+R73fM+XXuS/FmSe5OsTnLsQv9HSJJmNpcj\n+s3AB6rqJcDxwDlJjgLOBW6oqsXADd1rgDcAi7vHcuCCoVctSZqzWYO+qjZU1e3d8pPAWuAg4DTg\nkm61S4A3d8unAV+snm8Beyc5cOiV78KeenrLLtm3pPnZrikQkowDxwC3AgdU1QbofRkk2b9b7SDg\nob7N1ndtGwYtVj177L6I8XOvHUnf6847dST9Spq/Of8Ym+SFwBXA+6vqiW2tOk1bTbO/5UlWJVk1\nOTk51zIkSdtpTkGfZHd6IX9pVV3ZNW+cGpLpnjd17euBQ/o2Pxh4ZOt9VtWKqpqoqomxsVknX5Mk\nzdNczroJcCGwtqo+1ffWNcCybnkZcHVf+290Z98cDzw+NcQjSdrx5jJGfwJwFvDdJHd2bR8GzgMu\nT3I28CBwRvfedcApwL3AD4B3DrViSdJ2mTXoq+oWph93BzhpmvULOGfAuiRJQ+KVsZLUOINekhpn\n0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9\nJDXOoJekxhn0ktS4udwz9qIkm5Ks6Wu7LMmd3WPd1C0Gk4wn+WHfe59dyOIlSbObyz1jLwbOB744\n1VBVb5taTvJJ4PG+9e+rqiXDKlCSNJi53DP25iTj072XJMBbgdcMtyxJ0rAMOkb/KmBjVX2vr+2w\nJHck+XqSV820YZLlSVYlWTU5OTlgGZKkmQwa9EuBlX2vNwCHVtUxwG8Cf5nkZ6fbsKpWVNVEVU2M\njY0NWIYkaSbzDvokuwH/BLhsqq2qflRVj3bLtwH3AS8atEhJ0vwNckT/68DdVbV+qiHJWJJF3fLh\nwGLg/sFKlCQNYi6nV64EvgkcmWR9krO7t87kucM2AK8GVif5DvAV4N1V9dgwC5YkbZ+5nHWzdIb2\nd0zTdgVwxeBlSZKGxStjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9\nJDXOoJekxhn0ktQ4g17b5amnt+xS/UotmMvNwaX/b4/dFzF+7rU7vN915526w/uUWuERvSQ1zqCX\npMbN5Q5TFyXZlGRNX9tHkzyc5M7ucUrfex9Kcm+Se5K8fqEKlyTNzVyO6C8GTp6m/dNVtaR7XAeQ\n5Ch6txg8utvmL6buIStJGo1Zg76qbgbmet/X04AvVdWPquoB4F7guAHqkyQNaJAx+vckWd0N7ezT\ntR0EPNS3zvquTZI0IvMN+guAI4AlwAbgk117plm3pttBkuVJViVZNTk5Oc8yJEmzmVfQV9XGqtpS\nVc8An+PZ4Zn1wCF9qx4MPDLDPlZU1URVTYyNjc2nDEnSHMwr6JMc2PfydGDqjJxrgDOT/FSSw4DF\nwP8crERJ0iBmvTI2yUrgRGC/JOuBjwAnJllCb1hmHfAugKq6K8nlwN8Am4Fzqspr1yVphGYN+qpa\nOk3zhdtY/w+APxikKEnS8HhlrCQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBv0A\nvGG1pOcDbw4+AG+ULen5wCN6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaN2vQJ7koyaYk\na/ra/iTJ3UlWJ7kqyd5d+3iSHya5s3t8diGLlyTNbi5H9BcDJ2/Vdj3w0qp6GfC3wIf63ruvqpZ0\nj3cPp0xJ0nzNGvRVdTPw2FZtX6uqzd3LbwEHL0BtkqQhGMYY/b8A/qrv9WFJ7kjy9SSvGsL+JUkD\nGGiumyS/A2wGLu2aNgCHVtWjSX4J+M9Jjq6qJ6bZdjmwHODQQw8dpAxJ0jbM+4g+yTLgjcA/r6oC\nqKofVdWj3fJtwH3Ai6bbvqpWVNVEVU2MjY3NtwxJ0izmFfRJTgY+CLypqn7Q1z6WZFG3fDiwGLh/\nGIVKkuZn1qGbJCuBE4H9kqwHPkLvLJufAq5PAvCt7gybVwMfS7IZ2AK8u6oem3bHkqQdYtagr6ql\n0zRfOMO6VwBXDFqUJGl4vDJWkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIa\nZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGjenoE9yUZJNSdb0te2b5Pok3+ue\n9+nak+TPktybZHWSYxeqeEnS7OZ6RH8xcPJWbecCN1TVYuCG7jXAG+jdFHwxsBy4YPAytat76ukt\nu2Tf0jDMes9YgKq6Ocn4Vs2n0btpOMAlwE3AB7v2L1ZVAd9KsneSA6tqwzAK1q5pj90XMX7utSPp\ne915p46kX2lYBhmjP2AqvLvn/bv2g4CH+tZb37U9R5LlSVYlWTU5OTlAGZKkbVmIH2MzTVv9REPV\niqqaqKqJsbGxBShDkgSDBf3GJAcCdM+buvb1wCF96x0MPDJAP5KkAQwS9NcAy7rlZcDVfe2/0Z19\nczzwuOPzkjQ6c/oxNslKej+87pdkPfAR4Dzg8iRnAw8CZ3SrXwecAtwL/AB455BrliRth7medbN0\nhrdOmmbdAs4ZpChJ0vB4ZawkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXO\noJekxhn0ktQ4g16SGmfQS1Ljmgh6b94sSTOb0zTFO7tR3Tjam0arVU89vYU9dl+0y/TbuiaCXtJw\nefDUlnkHfZIjgcv6mg4Hfg/YG/hXwGTX/uGqum7eFUqSBjLvoK+qe4AlAEkWAQ8DV9G7deCnq+oT\nQ6lQkjSQYf0YexJwX1V9f0j7kyQNybCC/kxgZd/r9yRZneSiJPsMqQ9J0jwMHPRJXgC8Cfhy13QB\ncAS9YZ0NwCdn2G55klVJVk1OTk63iiRpCIZxRP8G4Paq2ghQVRuraktVPQN8Djhuuo2qakVVTVTV\nxNjY2BDKkCRNZxhBv5S+YZskB/a9dzqwZgh9SJLmaaDz6JPsCbwWeFdf8x8nWQIUsG6r9yRJO9hA\nQV9VPwB+bqu2swaqSJI0VE3MdSNJmplBL+2knKxPw+JcN9JOalTzzYBzzrTGI3pJapxBL0mNM+il\nWThWruc7x+ilWTg3u57vPKKXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr2kncaoLk5r\n/aI4L5iStNPw4rSF4RG9JDVu4CP6JOuAJ4EtwOaqmkiyL3AZME7vdoJvraq/H7QvSdL2G9YR/a9V\n1ZKqmuhenwvcUFWLgRu615KkEViooZvTgEu65UuANy9QP5KkWQwj6Av4WpLbkizv2g6oqg0A3fP+\nQ+hHkjQPwzjr5oSqeiTJ/sD1Se6ey0bdl8JygEMPPXQIZUiSpjPwEX1VPdI9bwKuAo4DNiY5EKB7\n3jTNdiuqaqKqJsbGxgYtQ5I0g4GCPsleSX5mahl4HbAGuAZY1q22DLh6kH4kSfM36NDNAcBVSab2\n9ZdV9dUk3wYuT3I28CBwxoD9SJLmaaCgr6r7gZdP0/4ocNIg+5YkDYdXxkpS4wx6SWqcQS9JjTPo\nJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16S\nGmfQS1Lj5h30SQ5JcmOStUnuSvK+rv2jSR5Ocmf3OGV45UqSttcgtxLcDHygqm7vbhB+W5Lru/c+\nXVWfGLw8SdKg5h30VbUB2NAtP5lkLXDQsAqTJA3HUMbok4wDxwC3dk3vSbI6yUVJ9plhm+VJViVZ\nNTk5OYwyJEnTGDjok7wQuAJ4f1U9AVwAHAEsoXfE/8nptquqFVU1UVUTY2Njg5YhSZrBQEGfZHd6\nIX9pVV0JUFUbq2pLVT0DfA44bvAyJWnhPPX0lqb7nvcYfZIAFwJrq+pTfe0HduP3AKcDawYrUZIW\n1h67L2L83GtH0ve6805d8D4GOevmBOAs4LtJ7uzaPgwsTbIEKGAd8K6BKpQkDWSQs25uATLNW9fN\nvxxJ0rB5ZawkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4\ng16SGmfQS1LjDHpJapxBL0mNM+glqXELFvRJTk5yT5J7k5y7UP1IkrZtQYI+ySLgz4E3AEfRu73g\nUQvRlyRp2xbqiP444N6qur+qfgx8CThtgfqSJG3DQgX9QcBDfa/Xd22SpB0sVTX8nSZnAK+vqn/Z\nvT4LOK6q3tu3znJgeffySOCeoReyY+0H/N2oi9iJ+Hk8l5/Hs/wsnmuQz+MXqmpstpV2m+fOZ7Me\nOKTv9cHAI/0rVNUKYMUC9b/DJVlVVROjrmNn4efxXH4ez/KzeK4d8Xks1NDNt4HFSQ5L8gLgTOCa\nBepLkrQNC3JEX1Wbk7wH+GtgEXBRVd21EH1JkrZtoYZuqKrrgOsWav87oWaGoYbEz+O5/Dye5Wfx\nXAv+eSzIj7GSpJ2HUyBIUuMM+gElOSTJjUnWJrkryftGXdOoJVmU5I4k/3XUtYxakr2TfCXJ3d3/\nR3551DWNUpJ/1/07WZNkZZI9Rl3TjpTkoiSbkqzpa9s3yfVJvtc97zPsfg36wW0GPlBVLwGOB85x\nugfeB6wddRE7iT8FvlpVLwZezi78uSQ5CPi3wERVvZTeiRpnjraqHe5i4OSt2s4FbqiqxcAN3euh\nMugHVFUbqur2bvlJev+Qd9mrgJMcDJwKfH7UtYxakp8FXg1cCFBVP66q/z3aqkZuN+Cnk+wG7MlW\n19e0rqpuBh7bqvk04JJu+RLgzcPu16AfoiTjwDHAraOtZKQ+A/w28MyoC9kJHA5MAl/ohrI+n2Sv\nURc1KlX1MPAJ4EFgA/B4VX1ttFXtFA6oqg3QO3AE9h92Bwb9kCR5IXAF8P6qemLU9YxCkjcCm6rq\ntlHXspPYDTgWuKCqjgH+LwvwZ/nzRTf2fBpwGPDzwF5J3j7aqnYNBv0QJNmdXshfWlVXjrqeEToB\neFOSdfRmLH1Nkv802pJGaj2wvqqm/sL7Cr3g31X9OvBAVU1W1dPAlcCvjLimncHGJAcCdM+bht2B\nQT+gJKE3Bru2qj416npGqao+VFUHV9U4vR/Z/ntV7bJHbFX1v4CHkhzZNZ0E/M0ISxq1B4Hjk+zZ\n/bs5iV34x+k+1wDLuuVlwNXD7mDBrozdhZwAnAV8N8mdXduHuyuDpfcCl3ZzPt0PvHPE9YxMVd2a\n5CvA7fTOVruDXewq2SQrgROB/ZKsBz4CnAdcnuRsel+GZwy9X6+MlaS2OXQjSY0z6CWpcQa9JDXO\noJekxhn0ktQ4g16SGmfQa4dLcnqSSvLi7vUDfRcVTa3zmSS/3S0fl+SmbhrX25Ncm+QXk7wuyTe7\ni2+mpke+M8mvJPlokt+apu8t3Tp3JflOkt9Mss1/B13/Nye5p5tu+PNJ9tzG+kuSnDKfz0ZaCAa9\nRmEpcAvPTlH7pb5luuB9C3BZkgOAy+ldhLa4qo4F/hA4opsQ6/vA2d2m7wW+XVXf2EbfP6yqJVV1\nNPBa4BR6F61Mq+v/y8AHq+pI4CXAV4Gf2UYfS7r9Lqgkixa6DzWiqnz42GEP4IXAw8CLgLu7tpfR\nm0Jiap0TgVu65Y8Dv7+N/R0I3AccDdwL7Nu1fxT4rWnW/z9bvT4ceJTu4sFp1v8Y8LEZ3jsO+Aa9\nKzy/ARwJvIDe1Y2TwJ3A24C9gIuAb3frntZtvye9L7HVwGX0Zj2d6N5bCnwXWAP8UX/9XU230vuC\nuqrvvdcCV476f2MfO9/DI3rtaG+mdyOOvwUeS3JsVa0Gnkny8m6dM4GV3fLR9C6Zn1b1pnX9DPBN\n4N9X1dZzfW9TVd1P7y/bmaaGfSkw02ycdwOvrt7MlL8H/Ieq+nG3fFn1/nK4DPgdevP+vAL4NeBP\nuumK/w3w91X1MnpfaL8EkOTngT8CXkPvr4NXJJmao3wvYE1VvZJe4L8kyVj33juBL2zPf792DQa9\ndrSl9IZq6J6XdssrgTO7G1KcRm+45CckubW7Jd+f9jX/ObCoqi6eZ02Z53b/EPhyd1u4T9P7UprO\n64Bzu7mQbgL2AA4FfpXus6iqNfSO7AFeAdxUvVkeNwOX0ruBCcAWejOlUlUF/Efg7Un2Bn4Z+Kt5\n/reoYU5qph0myc/RO0p9aZKidyu56n50XQl8Dfg6sLqqpqZqvYve1L5XA1TVK5O8BXjj1H6r6plu\nf/Op6XB64TnT1LB30TvSnm5GwY8DN1bV6d1NZ26aqRvgn1bVPVv1PdMXzLa+eJ6qqi19r78A/Bfg\nKeDL3ReD9Bwe0WtHegvwxar6haoar6pDgAeAX62q++iNlZ/Hs8M20Dtaf0eS/nnLZzzjZXt0Qx6f\nBc7vjo6ncz6wLMkr+7Z7e5J/RO+I/uGu+R192zzJc3+s/WvgvX1nBx3Ttd8CvLVrOwr4xa79VuAf\nJ9mv+8F1Kb0vwJ9QVY/Qux3f79K7H6n0Ewx67UhLgau2arsC+Gfd8krgxf3rVG9O97cBf5jk3iTf\noPeFcf4c+vvdJOunHl3bT0+dXgn8N3p/Rfz+TDuoqo30fjP4RHd65VrgVcATwB93df0Pen+dTLkR\nOKrr5230jvx3B1Z3wzwf79b7C2AsyWrgg/SGbh7vfnf4ULef7wC3V9W25ii/FHioqnblue61DU5T\nLI1Id7S+e1U9leQI4AbgRd0Putuzn/OBO6rqwoWoU89/jtFLo7MncGN3K8oA/3oeIX8bvXvRfmAB\n6lMjPKKXgCSvp3dKY78Hqur0UdQjDZNBL0mN88dYSWqcQS9JjTPoJalxBr0kNc6gl6TG/T+rCpRh\nqIb0AgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b9fe488550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(full['AVGYLD_Category'], kde=False, bins=10, hist_kws={\"rwidth\":1,'edgecolor':'white', 'alpha':1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    tmp.append(full[full['AVGYLD_Category'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "X_cols = [col for col in full.columns if col not in ['YLD00', 'AVGYLD_Category']]\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    X.append(tmp[i][X_cols])\n",
    "    y.append(tmp[i]['YLD00'])\n",
    "    X_train_part, X_test_part, y_train_part, y_test_part = train_test_split(tmp[i][X_cols], tmp[i]['YLD00'], test_size=.2,random_state=0)\n",
    "    X_train.append(X_train_part)\n",
    "    X_test.append(X_test_part)\n",
    "    y_train.append(y_train_part)\n",
    "    y_test.append(y_test_part)\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(full[X_cols], full['YLD00'], test_size=.2,random_state=0)\n",
    "\n",
    "\n",
    "X.append(full[X_cols])\n",
    "y.append(full['YLD00'])\n",
    "X_train.append(X_train_full)\n",
    "X_test.append(X_test_full)\n",
    "y_train.append(y_train_full)\n",
    "y_test.append(y_test_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Best score: -6113.919917122458\n",
      "Best parameters: {'min_samples_leaf': 2, 'min_samples_split': 10, 'random_state': 8}\n",
      "1\n",
      "Best score: -1962.409395937711\n",
      "Best parameters: {'min_samples_leaf': 8, 'min_samples_split': 2, 'random_state': 6}\n",
      "2\n",
      "Best score: -1252.4691846200042\n",
      "Best parameters: {'min_samples_leaf': 7, 'min_samples_split': 19, 'random_state': 4}\n",
      "3\n",
      "Best score: -433.528052286799\n",
      "Best parameters: {'min_samples_leaf': 7, 'min_samples_split': 18, 'random_state': 8}\n",
      "4\n",
      "Best score: -322.9236116362546\n",
      "Best parameters: {'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 9}\n",
      "5\n",
      "Best score: -310.89519594832694\n",
      "Best parameters: {'min_samples_leaf': 9, 'min_samples_split': 19, 'random_state': 8}\n",
      "6\n",
      "Best score: -265.08603646730216\n",
      "Best parameters: {'min_samples_leaf': 8, 'min_samples_split': 2, 'random_state': 7}\n",
      "7\n",
      "Best score: -398.5835972022729\n",
      "Best parameters: {'min_samples_leaf': 8, 'min_samples_split': 18, 'random_state': 1}\n",
      "8\n",
      "Best score: -414.19325665876903\n",
      "Best parameters: {'min_samples_leaf': 1, 'min_samples_split': 18, 'random_state': 2}\n",
      "9\n",
      "Best score: -3135.7314370915383\n",
      "Best parameters: {'min_samples_leaf': 1, 'min_samples_split': 7, 'random_state': 6}\n",
      "10\n",
      "Best score: -20572.81303279318\n",
      "Best parameters: {'min_samples_leaf': 5, 'min_samples_split': 16, 'random_state': 7}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "dt_tune_run = True\n",
    "dt_parameters = []\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    defaut = {'criterion': 'mse', 'max_depth': None,\n",
    "                  'max_leaf_nodes': None, 'min_impurity_split': 0.005, 'min_weight_fraction_leaf': 0.0,\n",
    "              'presort': False, 'splitter': 'random'}\n",
    "    dt_parameters.append(defaut)\n",
    "    if dt_tune_run:\n",
    "        parameter_grid = {\n",
    "    #          'max_features':range(0,1,1),\n",
    "            'random_state':range(0,10,1),\n",
    "            'min_samples_leaf':range(1,10,1),\n",
    "            'min_samples_split': range(2, 20, 1)\n",
    "        }\n",
    "        forest = DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_split=0.005, min_weight_fraction_leaf=0.0,\n",
    "                                        presort=False, splitter='random')\n",
    "\n",
    "        grid_search = GridSearchCV(forest,\n",
    "                                   scoring='mean_squared_error',\n",
    "                                   param_grid=parameter_grid,\n",
    "                                   cv=5)\n",
    "\n",
    "        grid_search.fit(X[i], y[i])\n",
    "        DecisionTreeModel = grid_search\n",
    "        parameters = grid_search.best_params_\n",
    "        dt_parameters[i]['min_samples_leaf'] = grid_search.best_params_['min_samples_leaf']\n",
    "        dt_parameters[i]['min_samples_split'] = grid_search.best_params_['min_samples_split']\n",
    "        dt_parameters[i]['random_state'] = grid_search.best_params_['random_state']\n",
    "        print('Best score: {}'.format(grid_search.best_score_))\n",
    "        print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: dt range - 1, measure: mae, score: 58.94\n",
      "Model: dt range - 1 measure: mse, score: 6165.48\n",
      "Model: dt range - 1 measure: rmse, score: 78.52\n",
      "1\n",
      "Model: dt range - 2, measure: mae, score: 35.86\n",
      "Model: dt range - 2 measure: mse, score: 1965.23\n",
      "Model: dt range - 2 measure: rmse, score: 44.33\n",
      "2\n",
      "Model: dt range - 3, measure: mae, score: 29.8\n",
      "Model: dt range - 3 measure: mse, score: 1253.2\n",
      "Model: dt range - 3 measure: rmse, score: 35.4\n",
      "3\n",
      "Model: dt range - 4, measure: mae, score: 17.27\n",
      "Model: dt range - 4 measure: mse, score: 434.36\n",
      "Model: dt range - 4 measure: rmse, score: 20.84\n",
      "4\n",
      "Model: dt range - 5, measure: mae, score: 14.84\n",
      "Model: dt range - 5 measure: mse, score: 323.9\n",
      "Model: dt range - 5 measure: rmse, score: 18.0\n",
      "5\n",
      "Model: dt range - 6, measure: mae, score: 15.29\n",
      "Model: dt range - 6 measure: mse, score: 310.9\n",
      "Model: dt range - 6 measure: rmse, score: 17.63\n",
      "6\n",
      "Model: dt range - 7, measure: mae, score: 13.57\n",
      "Model: dt range - 7 measure: mse, score: 265.78\n",
      "Model: dt range - 7 measure: rmse, score: 16.3\n",
      "7\n",
      "Model: dt range - 8, measure: mae, score: 16.93\n",
      "Model: dt range - 8 measure: mse, score: 396.92\n",
      "Model: dt range - 8 measure: rmse, score: 19.92\n",
      "8\n",
      "Model: dt range - 9, measure: mae, score: 17.16\n",
      "Model: dt range - 9 measure: mse, score: 411.6\n",
      "Model: dt range - 9 measure: rmse, score: 20.29\n",
      "9\n",
      "Model: dt range - 10, measure: mae, score: 50.88\n",
      "Model: dt range - 10 measure: mse, score: 3166.87\n",
      "Model: dt range - 10 measure: rmse, score: 56.27\n",
      "10\n",
      "Model: dt range - 11, measure: mae, score: 110.92\n",
      "Model: dt range - 11 measure: mse, score: 20572.81\n",
      "Model: dt range - 11 measure: rmse, score: 143.43\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "score_measure_list = ['neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "dt_model = []\n",
    "\n",
    "for i in range(11):\n",
    "    tmp_model = DecisionTreeRegressor(**dt_parameters[i])\n",
    "    tmp_model.fit(X_train[i], y_train[i])\n",
    "    dt_model.append(tmp_model)\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    for score_measure in score_measure_list:\n",
    "        res = compute_score(dt_model[i], X[i], y[i], scoring = score_measure)\n",
    "        res = round(res, 2) * -1\n",
    "        if score_measure == 'neg_mean_absolute_error':\n",
    "            print('Model: dt range - {}, measure: mae, score: {}'.format(i+1, res))\n",
    "        elif score_measure == 'neg_mean_squared_error':\n",
    "            print('Model: dt range - {} measure: mse, score: {}'.format(i+1, res))\n",
    "            tmp = round(res ** 0.5, 2)\n",
    "            print('Model: dt range - {} measure: rmse, score: {}'.format(i+1, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def me(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    return max(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: dt range - 1, measure: mape, score: 12.36\n",
      "Model: dt range - 1, measure: me, score: 114.26\n",
      "1\n",
      "Model: dt range - 2, measure: mape, score: 5.64\n",
      "Model: dt range - 2, measure: me, score: 118.39\n",
      "2\n",
      "Model: dt range - 3, measure: mape, score: 3.77\n",
      "Model: dt range - 3, measure: me, score: 63.53\n",
      "3\n",
      "Model: dt range - 4, measure: mape, score: 2.45\n",
      "Model: dt range - 4, measure: me, score: 49.6\n",
      "4\n",
      "Model: dt range - 5, measure: mape, score: 1.8\n",
      "Model: dt range - 5, measure: me, score: 42.84\n",
      "5\n",
      "Model: dt range - 6, measure: mape, score: 1.44\n",
      "Model: dt range - 6, measure: me, score: 33.6\n",
      "6\n",
      "Model: dt range - 7, measure: mape, score: 1.25\n",
      "Model: dt range - 7, measure: me, score: 28.33\n",
      "7\n",
      "Model: dt range - 8, measure: mape, score: 1.73\n",
      "Model: dt range - 8, measure: me, score: 39.75\n",
      "8\n",
      "Model: dt range - 9, measure: mape, score: 1.99\n",
      "Model: dt range - 9, measure: me, score: 50.0\n",
      "9\n",
      "Model: dt range - 10, measure: mape, score: 5.37\n",
      "Model: dt range - 10, measure: me, score: 211.38\n",
      "10\n",
      "Model: dt range - 11, measure: mape, score: 11.83\n",
      "Model: dt range - 11, measure: me, score: 400.66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    y_pred = dt_model[i].predict(X_test[i])\n",
    "    mape_res = round(mape(y_test[i], y_pred),2)\n",
    "    print('Model: dt range - {}, measure: mape, score: {}'.format(i+1, mape_res))\n",
    "    me_res = round(me(y_test[i], y_pred),2)\n",
    "    print('Model: dt range - {}, measure: me, score: {}'.format(i+1, me_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Best score: -7183.846027347191\n",
      "Best parameters: {'C': 10, 'gamma': 0.001}\n",
      "1\n",
      "Best score: -1998.780910440363\n",
      "Best parameters: {'C': 1000, 'gamma': 1}\n",
      "2\n",
      "Best score: -1192.6246235223898\n",
      "Best parameters: {'C': 1, 'gamma': 0.01}\n",
      "3\n",
      "Best score: -416.20998268542183\n",
      "Best parameters: {'C': 100, 'gamma': 1}\n",
      "4\n",
      "Best score: -331.49825151994287\n",
      "Best parameters: {'C': 10, 'gamma': 0.01}\n",
      "5\n",
      "Best score: -295.78891517096145\n",
      "Best parameters: {'C': 100, 'gamma': 1}\n",
      "6\n",
      "Best score: -265.8639146617706\n",
      "Best parameters: {'C': 0.1, 'gamma': 0.001}\n",
      "7\n",
      "Best score: -401.95951893392817\n",
      "Best parameters: {'C': 100, 'gamma': 1}\n",
      "8\n",
      "Best score: -518.4341398511824\n",
      "Best parameters: {'C': 100, 'gamma': 0.1}\n",
      "9\n",
      "Best score: -3476.4054444069416\n",
      "Best parameters: {'C': 100, 'gamma': 0.1}\n",
      "10\n",
      "Best score: -27923.225817188817\n",
      "Best parameters: {'C': 1000, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "svm_tune_run = True\n",
    "svm_parameters = []\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    defaut = {'cache_size': 200, 'coef0': 0.0,\n",
    "                  'degree': 3, 'kernel': 'rbf', 'max_iter': -1,\n",
    "              'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
    "    svm_parameters.append(defaut)\n",
    "    if svm_tune_run:\n",
    "        parameter_grid = {\n",
    "             'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "             'gamma' : [0.001, 0.01, 0.1, 1]\n",
    "         }\n",
    "\n",
    "        forest = SVR(cache_size=200, coef0=0.0,\n",
    "                  degree=3, kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "        grid_search = GridSearchCV(forest,\n",
    "                                   scoring='mean_squared_error',\n",
    "                                   param_grid=parameter_grid,\n",
    "                                   cv=5)\n",
    "\n",
    "        grid_search.fit(X[i], y[i])\n",
    "        SVCModel = grid_search\n",
    "        parameters = grid_search.best_params_\n",
    "        svm_parameters[i]['C'] = grid_search.best_params_['C']\n",
    "        svm_parameters[i]['gamma'] = grid_search.best_params_['gamma']\n",
    "\n",
    "        print('Best score: {}'.format(grid_search.best_score_))\n",
    "        print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: svm range - 1, measure: mae, score: 68.26\n",
      "Model: svm range - 1 measure: mse, score: 7182.14\n",
      "Model: svm range - 1 measure: rmse, score: 84.75\n",
      "1\n",
      "Model: svm range - 2, measure: mae, score: 38.56\n",
      "Model: svm range - 2 measure: mse, score: 1999.09\n",
      "Model: svm range - 2 measure: rmse, score: 44.71\n",
      "2\n",
      "Model: svm range - 3, measure: mae, score: 30.18\n",
      "Model: svm range - 3 measure: mse, score: 1192.6\n",
      "Model: svm range - 3 measure: rmse, score: 34.53\n",
      "3\n",
      "Model: svm range - 4, measure: mae, score: 17.54\n",
      "Model: svm range - 4 measure: mse, score: 416.29\n",
      "Model: svm range - 4 measure: rmse, score: 20.4\n",
      "4\n",
      "Model: svm range - 5, measure: mae, score: 15.82\n",
      "Model: svm range - 5 measure: mse, score: 331.9\n",
      "Model: svm range - 5 measure: rmse, score: 18.22\n",
      "5\n",
      "Model: svm range - 6, measure: mae, score: 15.36\n",
      "Model: svm range - 6 measure: mse, score: 295.79\n",
      "Model: svm range - 6 measure: rmse, score: 17.2\n",
      "6\n",
      "Model: svm range - 7, measure: mae, score: 13.45\n",
      "Model: svm range - 7 measure: mse, score: 265.75\n",
      "Model: svm range - 7 measure: rmse, score: 16.3\n",
      "7\n",
      "Model: svm range - 8, measure: mae, score: 17.15\n",
      "Model: svm range - 8 measure: mse, score: 400.32\n",
      "Model: svm range - 8 measure: rmse, score: 20.01\n",
      "8\n",
      "Model: svm range - 9, measure: mae, score: 19.2\n",
      "Model: svm range - 9 measure: mse, score: 517.21\n",
      "Model: svm range - 9 measure: rmse, score: 22.74\n",
      "9\n",
      "Model: svm range - 10, measure: mae, score: 46.55\n",
      "Model: svm range - 10 measure: mse, score: 3390.49\n",
      "Model: svm range - 10 measure: rmse, score: 58.23\n",
      "10\n",
      "Model: svm range - 11, measure: mae, score: 131.9\n",
      "Model: svm range - 11 measure: mse, score: 27923.23\n",
      "Model: svm range - 11 measure: rmse, score: 167.1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "score_measure_list = ['neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "svm_model = []\n",
    "\n",
    "for i in range(11):\n",
    "    tmp_model = SVR(**svm_parameters[i])\n",
    "    tmp_model.fit(X_train[i], y_train[i])\n",
    "    svm_model.append(tmp_model)\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    for score_measure in score_measure_list:\n",
    "        res = compute_score(svm_model[i], X[i], y[i], scoring = score_measure)\n",
    "        res = round(res, 2) * -1\n",
    "        if score_measure == 'neg_mean_absolute_error':\n",
    "            print('Model: svm range - {}, measure: mae, score: {}'.format(i+1, res))\n",
    "        elif score_measure == 'neg_mean_squared_error':\n",
    "            print('Model: svm range - {} measure: mse, score: {}'.format(i+1, res))\n",
    "            tmp = round(res ** 0.5, 2)\n",
    "            print('Model: svm range - {} measure: rmse, score: {}'.format(i+1, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: svm range - 1, measure: mape, score: 16.65\n",
      "Model: svm range - 1, measure: me, score: 234.43\n",
      "1\n",
      "Model: svm range - 2, measure: mape, score: 5.7\n",
      "Model: svm range - 2, measure: me, score: 85.39\n",
      "2\n",
      "Model: svm range - 3, measure: mape, score: 3.97\n",
      "Model: svm range - 3, measure: me, score: 60.76\n",
      "3\n",
      "Model: svm range - 4, measure: mape, score: 2.19\n",
      "Model: svm range - 4, measure: me, score: 39.84\n",
      "4\n",
      "Model: svm range - 5, measure: mape, score: 1.47\n",
      "Model: svm range - 5, measure: me, score: 36.73\n",
      "5\n",
      "Model: svm range - 6, measure: mape, score: 1.54\n",
      "Model: svm range - 6, measure: me, score: 26.64\n",
      "6\n",
      "Model: svm range - 7, measure: mape, score: 1.0\n",
      "Model: svm range - 7, measure: me, score: 28.64\n",
      "7\n",
      "Model: svm range - 8, measure: mape, score: 1.66\n",
      "Model: svm range - 8, measure: me, score: 33.26\n",
      "8\n",
      "Model: svm range - 9, measure: mape, score: 1.84\n",
      "Model: svm range - 9, measure: me, score: 50.79\n",
      "9\n",
      "Model: svm range - 10, measure: mape, score: 4.81\n",
      "Model: svm range - 10, measure: me, score: 172.68\n",
      "10\n",
      "Model: svm range - 11, measure: mape, score: 11.23\n",
      "Model: svm range - 11, measure: me, score: 409.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    y_pred = svm_model[i].predict(X_test[i])\n",
    "    mape_res = round(mape(y_test[i], y_pred),2)\n",
    "    print('Model: svm range - {}, measure: mape, score: {}'.format(i+1, mape_res))\n",
    "    me_res = round(me(y_test[i], y_pred),2)\n",
    "    print('Model: svm range - {}, measure: me, score: {}'.format(i+1, me_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Best score: -6601.59494222541\n",
      "Best parameters: {'min_samples_leaf': 7, 'min_samples_split': 2, 'random_state': 5}\n",
      "1\n",
      "Best score: -1745.4915095079257\n",
      "Best parameters: {'min_samples_leaf': 2, 'min_samples_split': 2, 'random_state': 2}\n",
      "2\n",
      "Best score: -1199.5482634657158\n",
      "Best parameters: {'min_samples_leaf': 7, 'min_samples_split': 19, 'random_state': 2}\n",
      "3\n",
      "Best score: -425.7000188428697\n",
      "Best parameters: {'min_samples_leaf': 8, 'min_samples_split': 19, 'random_state': 8}\n",
      "4\n",
      "Best score: -323.7623176776049\n",
      "Best parameters: {'min_samples_leaf': 9, 'min_samples_split': 2, 'random_state': 4}\n",
      "5\n",
      "Best score: -326.4677848332351\n",
      "Best parameters: {'min_samples_leaf': 9, 'min_samples_split': 19, 'random_state': 9}\n",
      "6\n",
      "Best score: -284.6219541480111\n",
      "Best parameters: {'min_samples_leaf': 1, 'min_samples_split': 4, 'random_state': 9}\n",
      "7\n",
      "Best score: -399.91071107251906\n",
      "Best parameters: {'min_samples_leaf': 7, 'min_samples_split': 15, 'random_state': 1}\n",
      "8\n",
      "Best score: -465.8777332306277\n",
      "Best parameters: {'min_samples_leaf': 2, 'min_samples_split': 19, 'random_state': 7}\n",
      "9\n",
      "Best score: -3467.373771370922\n",
      "Best parameters: {'min_samples_leaf': 3, 'min_samples_split': 14, 'random_state': 8}\n",
      "10\n",
      "Best score: -17333.754645947334\n",
      "Best parameters: {'min_samples_leaf': 3, 'min_samples_split': 15, 'random_state': 8}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "rf_tune_run = True\n",
    "rf_parameters = []\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    defaut = {'criterion': 'mse', 'max_depth': None, 'max_leaf_nodes': None,\n",
    "                      'min_impurity_split': 0.005, 'min_weight_fraction_leaf': 0.0}\n",
    "    rf_parameters.append(defaut)\n",
    "    if rf_tune_run:\n",
    "        parameter_grid = {\n",
    "    #          'max_features':range(0,1,1),\n",
    "            'random_state':range(0,10,1),\n",
    "            'min_samples_leaf':range(1,10,1),\n",
    "            'min_samples_split': range(2, 20, 1)\n",
    "        }\n",
    "\n",
    "        forest = RandomForestRegressor(criterion='mse', max_depth=None,\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    min_impurity_split=0.005, min_weight_fraction_leaf=0.0)\n",
    "\n",
    "        grid_search = GridSearchCV(forest,\n",
    "                                   scoring='mean_squared_error',\n",
    "                                   param_grid=parameter_grid,\n",
    "                                   cv=5)\n",
    "\n",
    "        grid_search.fit(X[i], y[i])\n",
    "        SVCModel = grid_search\n",
    "        parameters = grid_search.best_params_\n",
    "        rf_parameters[i]['random_state'] = grid_search.best_params_['random_state']\n",
    "        rf_parameters[i]['min_samples_leaf'] = grid_search.best_params_['min_samples_leaf']\n",
    "        rf_parameters[i]['min_samples_split'] = grid_search.best_params_['min_samples_split']\n",
    "\n",
    "        print('Best score: {}'.format(grid_search.best_score_))\n",
    "        print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: rf range - 1, measure: mae, score: 63.52\n",
      "Model: rf range - 1 measure: mse, score: 6616.69\n",
      "Model: rf range - 1 measure: rmse, score: 81.34\n",
      "1\n",
      "Model: rf range - 2, measure: mae, score: 34.54\n",
      "Model: rf range - 2 measure: mse, score: 1745.91\n",
      "Model: rf range - 2 measure: rmse, score: 41.78\n",
      "2\n",
      "Model: rf range - 3, measure: mae, score: 29.92\n",
      "Model: rf range - 3 measure: mse, score: 1199.69\n",
      "Model: rf range - 3 measure: rmse, score: 34.64\n",
      "3\n",
      "Model: rf range - 4, measure: mae, score: 17.25\n",
      "Model: rf range - 4 measure: mse, score: 425.66\n",
      "Model: rf range - 4 measure: rmse, score: 20.63\n",
      "4\n",
      "Model: rf range - 5, measure: mae, score: 15.85\n",
      "Model: rf range - 5 measure: mse, score: 324.04\n",
      "Model: rf range - 5 measure: rmse, score: 18.0\n",
      "5\n",
      "Model: rf range - 6, measure: mae, score: 15.71\n",
      "Model: rf range - 6 measure: mse, score: 326.47\n",
      "Model: rf range - 6 measure: rmse, score: 18.07\n",
      "6\n",
      "Model: rf range - 7, measure: mae, score: 14.2\n",
      "Model: rf range - 7 measure: mse, score: 285.1\n",
      "Model: rf range - 7 measure: rmse, score: 16.88\n",
      "7\n",
      "Model: rf range - 8, measure: mae, score: 16.98\n",
      "Model: rf range - 8 measure: mse, score: 398.3\n",
      "Model: rf range - 8 measure: rmse, score: 19.96\n",
      "8\n",
      "Model: rf range - 9, measure: mae, score: 18.89\n",
      "Model: rf range - 9 measure: mse, score: 465.56\n",
      "Model: rf range - 9 measure: rmse, score: 21.58\n",
      "9\n",
      "Model: rf range - 10, measure: mae, score: 45.62\n",
      "Model: rf range - 10 measure: mse, score: 3371.98\n",
      "Model: rf range - 10 measure: rmse, score: 58.07\n",
      "10\n",
      "Model: rf range - 11, measure: mae, score: 103.24\n",
      "Model: rf range - 11 measure: mse, score: 17333.75\n",
      "Model: rf range - 11 measure: rmse, score: 131.66\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "score_measure_list = ['neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "rf_model = []\n",
    "\n",
    "for i in range(11):\n",
    "    tmp_model = RandomForestRegressor(**rf_parameters[i])\n",
    "    tmp_model.fit(X_train[i], y_train[i])\n",
    "    rf_model.append(tmp_model)\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    for score_measure in score_measure_list:\n",
    "        res = compute_score(rf_model[i], X[i], y[i], scoring = score_measure)\n",
    "        res = round(res, 2) * -1\n",
    "        if score_measure == 'neg_mean_absolute_error':\n",
    "            print('Model: rf range - {}, measure: mae, score: {}'.format(i+1, res))\n",
    "        elif score_measure == 'neg_mean_squared_error':\n",
    "            print('Model: rf range - {} measure: mse, score: {}'.format(i+1, res))\n",
    "            tmp = round(res ** 0.5, 2)\n",
    "            print('Model: rf range - {} measure: rmse, score: {}'.format(i+1, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: rf range - 1, measure: mape, score: 13.82\n",
      "Model: rf range - 1, measure: me, score: 209.39\n",
      "1\n",
      "Model: rf range - 2, measure: mape, score: 5.33\n",
      "Model: rf range - 2, measure: me, score: 100.55\n",
      "2\n",
      "Model: rf range - 3, measure: mape, score: 3.93\n",
      "Model: rf range - 3, measure: me, score: 65.87\n",
      "3\n",
      "Model: rf range - 4, measure: mape, score: 2.14\n",
      "Model: rf range - 4, measure: me, score: 43.41\n",
      "4\n",
      "Model: rf range - 5, measure: mape, score: 1.62\n",
      "Model: rf range - 5, measure: me, score: 34.74\n",
      "5\n",
      "Model: rf range - 6, measure: mape, score: 1.69\n",
      "Model: rf range - 6, measure: me, score: 30.65\n",
      "6\n",
      "Model: rf range - 7, measure: mape, score: 1.25\n",
      "Model: rf range - 7, measure: me, score: 31.73\n",
      "7\n",
      "Model: rf range - 8, measure: mape, score: 1.67\n",
      "Model: rf range - 8, measure: me, score: 42.58\n",
      "8\n",
      "Model: rf range - 9, measure: mape, score: 1.78\n",
      "Model: rf range - 9, measure: me, score: 43.2\n",
      "9\n",
      "Model: rf range - 10, measure: mape, score: 4.76\n",
      "Model: rf range - 10, measure: me, score: 173.22\n",
      "10\n",
      "Model: rf range - 11, measure: mape, score: 9.36\n",
      "Model: rf range - 11, measure: me, score: 460.7\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(i)\n",
    "    y_pred = rf_model[i].predict(X_test[i])\n",
    "    mape_res = round(mape(y_test[i], y_pred),2)\n",
    "    print('Model: rf range - {}, measure: mape, score: {}'.format(i+1, mape_res))\n",
    "    me_res = round(me(y_test[i], y_pred),2)\n",
    "    print('Model: rf range - {}, measure: me, score: {}'.format(i+1, me_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Best score: -8988.621587891897\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.3, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6}\n",
      "1\n",
      "Best score: -1798.402676582251\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.3, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7}\n",
      "2\n",
      "Best score: -1269.2460231674152\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.3, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.6}\n",
      "3\n",
      "Best score: -451.5039537486522\n",
      "Best parameters: {'colsample_bytree': 0.7, 'gamma': 0.3, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.9}\n",
      "4\n",
      "Best score: -374.2011996479934\n",
      "Best parameters: {'colsample_bytree': 1.0, 'gamma': 0.3, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6}\n",
      "5\n",
      "Best score: -366.390143933136\n",
      "Best parameters: {'colsample_bytree': 0.9, 'gamma': 0.3, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.7}\n",
      "6\n",
      "Best score: -321.9528203769496\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.3, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6}\n",
      "7\n",
      "Best score: -460.7967887311866\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.3, 'max_depth': 2, 'min_child_weight': 4, 'subsample': 0.6}\n",
      "8\n",
      "Best score: -531.9087691456137\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.3, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.6}\n",
      "9\n",
      "Best score: -4195.608391096873\n",
      "Best parameters: {'colsample_bytree': 0.8, 'gamma': 0.3, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.9}\n",
      "10\n",
      "Best score: -16128.817521293531\n",
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 0.3, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "xgb_tune_run = True\n",
    "xgb_parameters = []\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    defaut = {'subsample': 0.8, 'colsample_bytree': 1.0, 'max_depth': 2, 'gamma': 0.3, 'min_child_weight': 4}\n",
    "    xgb_parameters.append(defaut)\n",
    "    if xgb_tune_run:\n",
    "        parameter_grid = {\n",
    "                    'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)], \n",
    "                    'subsample':[i/10.0 for i in range(6,11)],\n",
    "                    'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]\n",
    "        }\n",
    "\n",
    "        forest = XGBRegressor(nthread=-1)\n",
    "\n",
    "        grid_search = GridSearchCV(forest,\n",
    "                                   scoring='mean_squared_error',\n",
    "                                   param_grid=parameter_grid,\n",
    "                                   cv=5)\n",
    "\n",
    "        grid_search.fit(X[i], y[i])\n",
    "        SVCModel = grid_search\n",
    "        parameters = grid_search.best_params_\n",
    "        xgb_parameters[i]['min_child_weight'] = grid_search.best_params_['min_child_weight']\n",
    "        xgb_parameters[i]['gamma'] = grid_search.best_params_['gamma']\n",
    "        xgb_parameters[i]['subsample'] = grid_search.best_params_['subsample']\n",
    "        xgb_parameters[i]['colsample_bytree'] = grid_search.best_params_['colsample_bytree']\n",
    "        xgb_parameters[i]['max_depth'] = grid_search.best_params_['max_depth']\n",
    "        \n",
    "        print('Best score: {}'.format(grid_search.best_score_))\n",
    "        print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: xbg range - 1, measure: mae, score: 76.41\n",
      "Model: xbg range - 1 measure: mse, score: 8971.44\n",
      "Model: xbg range - 1 measure: rmse, score: 94.72\n",
      "1\n",
      "Model: xbg range - 2, measure: mae, score: 35.58\n",
      "Model: xbg range - 2 measure: mse, score: 1800.16\n",
      "Model: xbg range - 2 measure: rmse, score: 42.43\n",
      "2\n",
      "Model: xbg range - 3, measure: mae, score: 30.22\n",
      "Model: xbg range - 3 measure: mse, score: 1270.84\n",
      "Model: xbg range - 3 measure: rmse, score: 35.65\n",
      "3\n",
      "Model: xbg range - 4, measure: mae, score: 17.68\n",
      "Model: xbg range - 4 measure: mse, score: 451.39\n",
      "Model: xbg range - 4 measure: rmse, score: 21.25\n",
      "4\n",
      "Model: xbg range - 5, measure: mae, score: 16.74\n",
      "Model: xbg range - 5 measure: mse, score: 375.73\n",
      "Model: xbg range - 5 measure: rmse, score: 19.38\n",
      "5\n",
      "Model: xbg range - 6, measure: mae, score: 15.94\n",
      "Model: xbg range - 6 measure: mse, score: 366.39\n",
      "Model: xbg range - 6 measure: rmse, score: 19.14\n",
      "6\n",
      "Model: xbg range - 7, measure: mae, score: 14.67\n",
      "Model: xbg range - 7 measure: mse, score: 322.17\n",
      "Model: xbg range - 7 measure: rmse, score: 17.95\n",
      "7\n",
      "Model: xbg range - 8, measure: mae, score: 18.14\n",
      "Model: xbg range - 8 measure: mse, score: 459.54\n",
      "Model: xbg range - 8 measure: rmse, score: 21.44\n",
      "8\n",
      "Model: xbg range - 9, measure: mae, score: 19.48\n",
      "Model: xbg range - 9 measure: mse, score: 533.22\n",
      "Model: xbg range - 9 measure: rmse, score: 23.09\n",
      "9\n",
      "Model: xbg range - 10, measure: mae, score: 53.02\n",
      "Model: xbg range - 10 measure: mse, score: 4104.0\n",
      "Model: xbg range - 10 measure: rmse, score: 64.06\n",
      "10\n",
      "Model: xbg range - 11, measure: mae, score: 99.06\n",
      "Model: xbg range - 11 measure: mse, score: 16128.82\n",
      "Model: xbg range - 11 measure: rmse, score: 127.0\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "score_measure_list = ['neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "xgb_model = []\n",
    "\n",
    "for i in range(11):\n",
    "    tmp_model = XGBRegressor(**xgb_parameters[i])\n",
    "    tmp_model.fit(X_train[i], y_train[i])\n",
    "    xgb_model.append(tmp_model)\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    for score_measure in score_measure_list:\n",
    "        res = compute_score(xgb_model[i], X[i], y[i], scoring = score_measure)\n",
    "        res = round(res, 2) * -1\n",
    "        if score_measure == 'neg_mean_absolute_error':\n",
    "            print('Model: xbg range - {}, measure: mae, score: {}'.format(i+1, res))\n",
    "        elif score_measure == 'neg_mean_squared_error':\n",
    "            print('Model: xbg range - {} measure: mse, score: {}'.format(i+1, res))\n",
    "            tmp = round(res ** 0.5, 2)\n",
    "            print('Model: xbg range - {} measure: rmse, score: {}'.format(i+1, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: xgb range - 1, measure: mape, score: 14.36\n",
      "Model: xgb range - 1, measure: me, score: 168.13\n",
      "1\n",
      "Model: xgb range - 2, measure: mape, score: 5.5\n",
      "Model: xgb range - 2, measure: me, score: 100.62\n",
      "2\n",
      "Model: xgb range - 3, measure: mape, score: 4.06\n",
      "Model: xgb range - 3, measure: me, score: 74.89\n",
      "3\n",
      "Model: xgb range - 4, measure: mape, score: 2.34\n",
      "Model: xgb range - 4, measure: me, score: 46.53\n",
      "4\n",
      "Model: xgb range - 5, measure: mape, score: 1.66\n",
      "Model: xgb range - 5, measure: me, score: 38.74\n",
      "5\n",
      "Model: xgb range - 6, measure: mape, score: 1.57\n",
      "Model: xgb range - 6, measure: me, score: 32.89\n",
      "6\n",
      "Model: xgb range - 7, measure: mape, score: 1.32\n",
      "Model: xgb range - 7, measure: me, score: 36.76\n",
      "7\n",
      "Model: xgb range - 8, measure: mape, score: 1.73\n",
      "Model: xgb range - 8, measure: me, score: 42.05\n",
      "8\n",
      "Model: xgb range - 9, measure: mape, score: 2.01\n",
      "Model: xgb range - 9, measure: me, score: 37.92\n",
      "9\n",
      "Model: xgb range - 10, measure: mape, score: 5.42\n",
      "Model: xgb range - 10, measure: me, score: 188.94\n",
      "10\n",
      "Model: xgb range - 11, measure: mape, score: 8.9\n",
      "Model: xgb range - 11, measure: me, score: 477.17\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(i)\n",
    "    y_pred = xgb_model[i].predict(X_test[i])\n",
    "    mape_res = round(mape(y_test[i], y_pred),2)\n",
    "    print('Model: xgb range - {}, measure: mape, score: {}'.format(i+1, mape_res))\n",
    "    me_res = round(me(y_test[i], y_pred),2)\n",
    "    print('Model: xgb range - {}, measure: me, score: {}'.format(i+1, me_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Best score: -21009.244587402154\n",
      "Best parameters: {'copy_X': True, 'normalize': True}\n",
      "1\n",
      "Best score: -3045.6832345113803\n",
      "Best parameters: {'copy_X': True, 'normalize': True}\n",
      "2\n",
      "Best score: -1741.3223697311523\n",
      "Best parameters: {'copy_X': True, 'normalize': False}\n",
      "3\n",
      "Best score: -519.8571479619753\n",
      "Best parameters: {'copy_X': True, 'normalize': False}\n",
      "4\n",
      "Best score: -476.22521088293263\n",
      "Best parameters: {'copy_X': True, 'normalize': True}\n",
      "5\n",
      "Best score: -604.1071280440556\n",
      "Best parameters: {'copy_X': True, 'normalize': False}\n",
      "6\n",
      "Best score: -808.3136014621517\n",
      "Best parameters: {'copy_X': True, 'normalize': True}\n",
      "7\n",
      "Best score: -556.9544107894527\n",
      "Best parameters: {'copy_X': True, 'normalize': True}\n",
      "8\n",
      "Best score: -2223.730117995714\n",
      "Best parameters: {'copy_X': True, 'normalize': True}\n",
      "9\n",
      "Best score: -59102.35771921406\n",
      "Best parameters: {'copy_X': True, 'normalize': True}\n",
      "10\n",
      "Best score: -21573.310596540745\n",
      "Best parameters: {'copy_X': True, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr_tune_run = True\n",
    "lr_parameters = []\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    lr_parameters.append({})\n",
    "    if lr_tune_run:\n",
    "        parameter_grid = {\n",
    "             'copy_X': [True, False],\n",
    "             'normalize': [True, False]\n",
    "         }\n",
    "\n",
    "        forest = LinearRegression()\n",
    "\n",
    "        grid_search = GridSearchCV(forest,\n",
    "                                   scoring='mean_squared_error',\n",
    "                                   param_grid=parameter_grid,\n",
    "                                   cv=5)\n",
    "\n",
    "        grid_search.fit(X[i], y[i])\n",
    "        parameters = grid_search.best_params_\n",
    "        lr_parameters[i]['copy_X'] = grid_search.best_params_['copy_X']\n",
    "        lr_parameters[i]['normalize'] = grid_search.best_params_['normalize']\n",
    "        \n",
    "        print('Best score: {}'.format(grid_search.best_score_))\n",
    "        print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: lr range - 1, measure: mae, score: 100.44\n",
      "Model: lr range - 1 measure: mse, score: 20662.12\n",
      "Model: lr range - 1 measure: rmse, score: 143.74\n",
      "1\n",
      "Model: lr range - 2, measure: mae, score: 46.09\n",
      "Model: lr range - 2 measure: mse, score: 3059.18\n",
      "Model: lr range - 2 measure: rmse, score: 55.31\n",
      "2\n",
      "Model: lr range - 3, measure: mae, score: 35.37\n",
      "Model: lr range - 3 measure: mse, score: 1742.7\n",
      "Model: lr range - 3 measure: rmse, score: 41.75\n",
      "3\n",
      "Model: lr range - 4, measure: mae, score: 18.76\n",
      "Model: lr range - 4 measure: mse, score: 520.04\n",
      "Model: lr range - 4 measure: rmse, score: 22.8\n",
      "4\n",
      "Model: lr range - 5, measure: mae, score: 17.56\n",
      "Model: lr range - 5 measure: mse, score: 478.96\n",
      "Model: lr range - 5 measure: rmse, score: 21.89\n",
      "5\n",
      "Model: lr range - 6, measure: mae, score: 19.02\n",
      "Model: lr range - 6 measure: mse, score: 604.11\n",
      "Model: lr range - 6 measure: rmse, score: 24.58\n",
      "6\n",
      "Model: lr range - 7, measure: mae, score: 20.44\n",
      "Model: lr range - 7 measure: mse, score: 801.85\n",
      "Model: lr range - 7 measure: rmse, score: 28.32\n",
      "7\n",
      "Model: lr range - 8, measure: mae, score: 19.33\n",
      "Model: lr range - 8 measure: mse, score: 552.78\n",
      "Model: lr range - 8 measure: rmse, score: 23.51\n",
      "8\n",
      "Model: lr range - 9, measure: mae, score: 31.43\n",
      "Model: lr range - 9 measure: mse, score: 2221.87\n",
      "Model: lr range - 9 measure: rmse, score: 47.14\n",
      "9\n",
      "Model: lr range - 10, measure: mae, score: 178.06\n",
      "Model: lr range - 10 measure: mse, score: 60263.12\n",
      "Model: lr range - 10 measure: rmse, score: 245.49\n",
      "10\n",
      "Model: lr range - 11, measure: mae, score: 114.96\n",
      "Model: lr range - 11 measure: mse, score: 21573.31\n",
      "Model: lr range - 11 measure: rmse, score: 146.88\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "score_measure_list = ['neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "lr_model = []\n",
    "\n",
    "for i in range(11):\n",
    "    tmp_model = LinearRegression(**lr_parameters[i])\n",
    "    tmp_model.fit(X_train[i], y_train[i])\n",
    "    lr_model.append(tmp_model)\n",
    "\n",
    "for i in range(11):\n",
    "    print(i)\n",
    "    for score_measure in score_measure_list:\n",
    "        res = compute_score(lr_model[i], X[i], y[i], scoring = score_measure)\n",
    "        res = round(res, 2) * -1\n",
    "        if score_measure == 'neg_mean_absolute_error':\n",
    "            print('Model: lr range - {}, measure: mae, score: {}'.format(i+1, res))\n",
    "        elif score_measure == 'neg_mean_squared_error':\n",
    "            print('Model: lr range - {} measure: mse, score: {}'.format(i+1, res))\n",
    "            tmp = round(res ** 0.5, 2)\n",
    "            print('Model: lr range - {} measure: rmse, score: {}'.format(i+1, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: lr range - 1, measure: mape, score: 16.87\n",
      "Model: lr range - 1, measure: me, score: 165.4\n",
      "1\n",
      "Model: lr range - 2, measure: mape, score: 6.5\n",
      "Model: lr range - 2, measure: me, score: 108.5\n",
      "2\n",
      "Model: lr range - 3, measure: mape, score: 4.25\n",
      "Model: lr range - 3, measure: me, score: 68.4\n",
      "3\n",
      "Model: lr range - 4, measure: mape, score: 2.15\n",
      "Model: lr range - 4, measure: me, score: 44.77\n",
      "4\n",
      "Model: lr range - 5, measure: mape, score: 1.65\n",
      "Model: lr range - 5, measure: me, score: 44.45\n",
      "5\n",
      "Model: lr range - 6, measure: mape, score: 1.38\n",
      "Model: lr range - 6, measure: me, score: 39.03\n",
      "6\n",
      "Model: lr range - 7, measure: mape, score: 1.92\n",
      "Model: lr range - 7, measure: me, score: 49.5\n",
      "7\n",
      "Model: lr range - 8, measure: mape, score: 1.78\n",
      "Model: lr range - 8, measure: me, score: 42.64\n",
      "8\n",
      "Model: lr range - 9, measure: mape, score: 2.12\n",
      "Model: lr range - 9, measure: me, score: 81.81\n",
      "9\n",
      "Model: lr range - 10, measure: mape, score: 11.55\n",
      "Model: lr range - 10, measure: me, score: 190.66\n",
      "10\n",
      "Model: lr range - 11, measure: mape, score: 10.05\n",
      "Model: lr range - 11, measure: me, score: 478.69\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(i)\n",
    "    y_pred = lr_model[i].predict(X_test[i])\n",
    "    mape_res = round(mape(y_test[i], y_pred),2)\n",
    "    print('Model: lr range - {}, measure: mape, score: {}'.format(i+1, mape_res))\n",
    "    me_res = round(me(y_test[i], y_pred),2)\n",
    "    print('Model: lr range - {}, measure: me, score: {}'.format(i+1, me_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
